# -*- coding: utf-8 -*-
"""Video Captioning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12_I-G0fb8sx8n4eG_MABhcE8uPrGqnBJ
"""

!pip install opencv-python torch transformers Pillow oauth2client gspread

import cv2
import torch
import gspread
from PIL import Image
from oauth2client.service_account import ServiceAccountCredentials
from transformers import BlipForConditionalGeneration, BlipProcessor

token = "your_hugging_face_token"

# === CONFIGURATION ===
VIDEO_PATH = "video.mp4"  # Your video file
CREDENTIALS_PATH = "your-creds.json"
SPREADSHEET_NAME = "Video Captioning"

# === FRAME EXTRACTION ===
def extract_frames(video_path):
    cap = cv2.VideoCapture(video_path)
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = int(frame_count / fps)
    frames = []

    for sec in range(duration):
        cap.set(cv2.CAP_PROP_POS_MSEC, sec * 1000)  # jump to second
        ret, frame = cap.read()
        if ret:
            frames.append((sec, frame))
    cap.release()
    return frames

# === LOAD BLIP2 MODEL ===
device = "cuda" if torch.cuda.is_available() else "cpu"
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large", token=token)
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-large", token=token).to(device)

# === GENERATE CAPTIONS ===
def generate_captions(frames):
    captions = []
    for sec, frame in frames:
        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        inputs = processor(image, return_tensors="pt").to(device)
        out = model.generate(**inputs)
        caption = processor.tokenizer.decode(out[0], skip_special_tokens=True)
        print(f"[{sec}s] {caption}")
        captions.append((sec, caption))
    return captions

# === UPLOAD TO GOOGLE SHEETS ===
def upload_to_sheet(captions):
    scope = [
        "https://spreadsheets.google.com/feeds",
        "https://www.googleapis.com/auth/drive"
    ]
    creds = ServiceAccountCredentials.from_json_keyfile_name(CREDENTIALS_PATH, scope)
    client = gspread.authorize(creds)
    sheet = client.open(SPREADSHEET_NAME).sheet1

    sheet.clear()
    sheet.append_row(["Time (s)", "Caption"])
    for sec, caption in captions:
        sheet.append_row([str(sec), caption])

# === MAIN PIPELINE ===
if __name__ == "__main__":
    print("üéûÔ∏è Extracting frames...")
    frames = extract_frames(VIDEO_PATH)

    print("üß† Generating captions...")
    captions = generate_captions(frames)

    print("üì§ Uploading to Google Sheets...")
    upload_to_sheet(captions)

    print("‚úÖ Done!")

